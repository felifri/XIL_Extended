# Decoy Mnist
## Regularizer rate stability
We performed a small grid search to find the best regularizer rate ($\lambda_1$) of the right reason loss and evaluate how stable/instable the respective XIL losses are wrt to the regularizer rate. It is beneficial if a XIL loss is more stable, as it reduces the risk to set an unsuitable regularizer rate by the data scientist for a specific problem. Keep in mind that the true performance of a XIL method for a real life problem should always be evaluated on the explanations generated by the final model. We checked the performance on the not-confounded test set (keep in mind that in real life scenarios one would not tune on the test set) to account for differences in the XIL losses and offer a fairer comparison in later experiments.  
* all runs are cross validated on five different seeds [1, 10, 100, 1000, 10000]  
* hyperparams: EPOCHS = 64, BATCH_SIZE = 256, LR = 0.001, optim=Adam, train_shuffle=True, in brackets std
* note: CE does not have a regularizer rate


### MLP  
**Mean accuracies train and test:** 
|    Method     |$\lambda_1$| 0.01     | 0.1          |        1     |       10     |      100     |    1k        |    10k       |      100k    |        1M    |
| ------------- |:------|:------------:| :-----------:| :-----------:| :-----------:|:------------:|:------------:| :-----------:| :-----------:| :-----------:|
| RRR           | train | 99.6% (±0.07)| 99.4% (±0.07)| 99.4% (±0.08)| 99.3% (±0.04)| 99.2% (±0.13)| 98.7% (±0.08)| 96.3% (±0.27)| 90.8% (±1.63)| 67.2% (±5.80)|
|               | test  | 89.8% (±1.63)| 96.4% (±0.19)| 96.4% (±0.18)| 96.2% (±0.28)| 96.4% (±0.18)| 96.7% (±0.36)| 95.6% (±0.24)| 91.2% (±0.57)| 75.2% (±4.88)|
| RBR           | train | 99.8% (±0.05)| 99.7% (±0.16)| 99.7% (±0.25)| 99.6% (±0.28)| 99.7% (±0.21)| 99.7% (±0.14)| 99.3% (±0.47)| 99.4% (±0.19)| 97.6% (±2.26)|
|               | test  | 59.2% (±0.52)| 62.1% (±1.48)| 61.6% (±1.74)| 62.1% (±1.61)| 65.6% (±0.88)| 69.5% (±0.76)| 75.5% (±0.58)| 80.6% (±1.12)| 91.0% (±0.92)|
| CDEP          | train | 99.8% (±0.07)| 99.7% (±0.10)| 99.8% (±0.06)| 99.7% (±0.08)| 99.7% (±0.07)| 99.6% (±0.11)| 99.4% (±0.10)| 98.7% (±0.11)| 97.4% (±0.26)|
|               | test  | 58.8% (±1.57)| 59.3% (±0.74)| 58.6% (±0.97)| 58.7% (±0.57)| 60.0% (±1.09)| 60.7% (±0.81)| 61.3% (±0.35)| 62.1% (±0.90)| 67.7% (±1.84)|

* Note: Runs in which the train acc is smaller and the test acc is higher compared to other runs with different regularizer rates (e.g. CDEP 1M vs. CDEP 100) does not necessarily perform better, as these models probably need more epochs to reach a higher train acc. Then the test acc would probably drop further. We can also verify this behavior by looking at the plots and check the test acc in earlier epochs where the train acc is smaller.  
For instance in the case of CDEP: 
    CDEP 1M --> train: 97.4%; test: 67.7%
    CDEP 100--> train: 99.7%; test: 60.0% --> looking at the plot we can see that in epoch 4: train: 97.5%; test: 68.6%
    --> we can therefore conclude, that CDEP reg rate 1M is not better than 100.

Another instances which does not have the above described behavior is RBR:
    RBR 1M --> train: 97.6%; test: 91.0%
    RBR 1k --> train: 99.7%; test: 69.5% --> looking at the plot we can see that in epoch 4: train: 97.1% BUT test: 67%
    --> we conclude that RBR 1M is better than 1k 

* --> It is necessary to compare the plots of the performance on the the different rates within each method to pick a good one. Keep in mind that a very high reg rate also increases the chance of an instable training process, especially in the experiments of SwitchXILon and interaction efficiancy.

**MLP RA vs RR loss:**
Mean (avg over epochs) right answer loss vs right reason loss...

|    Method     |$\lambda_1$| 0.01     | 0.1          |        1     |       10     |      100     |    1k        |    10k       |      100k    |        1M    |
| ------------- |:------|:------------:| :-----------:| :-----------:| :-----------:|:------------:|:------------:| :-----------:| :-----------:| :-----------:|
| RRR           | ra    |  0.0001434   | 0.0002005    | 0.0002370    | 0.0003358    | **0.0007190**| 0.0019036    | 0.0057731    | 0.015564     | 0.031        |
|               | rr    |  0.0000344   | 0.0000331    | 0.0000213    | 0.0000707    | **0.0006787**| 0.0071658    | 0.0700646    | 0.697177     | 6.950        |
| RBR           | ra    | 0.000123     | 0.000124     | 0.000124     | 0.000138     | 0.000132     | 0.000151     | 0.0002       | 0.00055      | 0.0017       |
|               | rr    | 0.00000002   | 0.0000057    | 0.00000157   | 0.00000385   | 0.0000057    | 0.0000107    | 0.00002      | 0.000091     | 0.00048      |
| CDEP          | ra    | 0.00012      | 0.00012      | 0.00012      | 0.00012      | 0.00017      | **0.00039**  | 0.001        | 0.003        | 0.012        |
|               | rr    | 0.000002     | 0.000002     | 0.000015     | 0.0000132    | 0.000044     | **0.00049**  | 0.006        | 0.06         | 0.6          |

* --> to achieve good results on the test ra and rr needs to be in the same order of magnitude (e.g. RRR = 100, RBR > 1M, CDEP = 1k) 

### CNN
**Mean accuracies train and test:** 
|    Method     |$\lambda_1$| 0.01     | 0.1          |        1     |       10     |      100     |    1k        |    10k       |      100k    |        1M    |
| ------------- |:------|:------------:| :-----------:| :-----------:| :-----------:|:------------:|:------------:| :-----------:| :-----------:| :-----------:|
| RRR           | train | 99.9% (±0.06)| 99.9% (±0.08)| 99.8% (±0.02)| 99.9% (±0.05)| 99.9% (±0.08)| 99.8% (±0.06)| 99.8% (±0.10)| 99.7% (±0.05)| 97.7% (±2.16)|
|               | test  | 98.8% (±0.14)| 99.0% (±0.17)| 98.9% (±0.13)| 98.9% (±0.17)| 98.8% (±0.13)| 98.9% (±0.07)| 98.9% (±0.10)| 98.9% (±0.11)| 97.4% (±1.83)|
| RBR           | train | 99.9% (±0.13)| 99.9% (±0.12)| 100 % (±0.02)| 100 % (±0.00)| 100 % (±0.00)| 100 % (±0.00)| 100 % (±0.00)| 100 % (±0.00)| 100 % (±0.00)|
|               | test  | 81.6% (±1.75)| 81.4% (±0.54)| 85.1% (±1.49)| 88.2% (±2.00)| 90.5% (±1.38)| 94.6% (±1.11)| 97.3% (±0.65)| 98.9% (±0.14)| 99.1% (±0.12)|
| RRRGradCAM    | train | 99.9% (±0.03)| 99.9% (±0.02)| 99.7% (±0.18)| 95.1% (±1.82)| 93.7% (±1.88)| 75.0% (±32.2)| 78.8% (±33.8)| 94.7% (±1.29)| 95.0% (±0.83)|
|               | test  | 87.5% (±4.25)| 91.4% (±1.85)| 97.4% (±0.70)| 94.8% (±1.83)| 93.9% (±1.76)| 73.3% (±31.6)| 78.7% (±33.7)| 94.6% (±1.23)| 94.6% (±1.06)|
| HINT          | train | 99.9% (±0.04)| 99.9% (±0.05)| 99.9% (±0.02)| 99.7% (±0.04)| 99.0% (±0.11)| 97.6% (±0.25)| 97.1% (±0.30)| 97.3% (±0.18)| 97.1% (±0.14)|
|               | test  | 78.1% (±0.27)| 77.1% (±1.73)| 78.5% (±0.68)| 78.4% (±1.92)| 86.0% (±1.41)| 96.6% (±0.39)| 96.0% (±0.20)| 96.8% (±0.19)| 96.5% (±0.37)|
| CDEP          | train | 99.9% (±0.03)| 99.9% (±0.05)| 99.9% (±0.03)| 99.9% (±0.03)| 99.9% (±0.03)| 99.9% (±0.09)| 99.9% (±0.13)| 99.8% (±0.13)| 99.3% (±0.20)|
|               | test  | 79.5% (±2.06)| 79.0% (±1.17)| 78.4% (±1.00)| 77.9% (±1.73)| 78.2% (±0.49)| 80.3% (±3.29)| 82.0% (±3.80)| 90.9% (±0.94)| 97.1% (±0.70)|


* Note: Keep in mind that the baseline model wihich was trained on CrossEntropyLoss also reaches good test acc (97%) when stopped early in epoch 4/5 (train acc then 97%). 
* Runs in which the train acc is smaller and the test acc is higher compared to other runs with different regularizer rates (e.g. HINT 1k vs. HINT 100) does not necessarily perform better, as these models probably need more epochs to go to a higher train acc. The test acc would probably drop further. We can also check this, by looking at the logs and plots of the HINT 100 model, which reaches also 97% test acc when the train acc is around 97% and not 99%. Another possibility is that the HINT 100 model does not overcome the confounders and the test acc 97% in epoch 4 is manly influneced from the baseline loss (CEL). 
* --> It is necessary to compare the plots of the performance on the the different rates within each method to pick a good one. Keep in mind that a very high reg rate also increases the chance of an instable training process.
* To truly evaluate the performance of the above methods on DecoyMNIST, one needs to verify the behavior by looking at the generated heatmaps for images on the test set. These heatmaps meed to be generated by a trusted XAI visualization method.

**CNN RA vs RR loss:**
Mean (avg over epochs) right answer loss vs right reason loss...
|    Method     |$\lambda_1$| 0.01     | 0.1          |        1     |       10     |      100     |    1k        |    10k       |      100k    |        1M    |
| ------------- |:------|:------------:| :-----------:| :-----------:| :-----------:|:------------:|:------------:| :-----------:| :-----------:| :-----------:|
| RRR           | ra    |  0.00007     | 0.00007      | 0.00008      | 0.00008      | **0.000097** | 0.00016      | 0.0007       | 0.0039       | 0.014        |
|               | rr    |  0.000007    | 0.000007     | 0.000009     | 0.00001      | **0.000024** | 0.00011      | 0.0010       | 0.0089       | 0.081        |
| RBR           | ra    | 0.00007      | 0.00007      | 0.00007      | 0.00006      | 0.00007      | 0.00007      | 0.00007      | 0.00008      | 0.00008      |
|               | rr    | 0.00000019   | 0.0000003    | 0.0000006    | 0.0000008    | 0.000002     | 0.000002     | 0.000003     | 0.0000036    | 0.0000038    |
| RRRGradCAM    | ra    | 0.00008      | 0.00019      | **0.00019**  | 0.00092      | 0.0012       | 0.003        | 0.0025       | 0.0013       | 0.0012       |
|               | rr    | 0.000026     | 0.00009      | **0.00048**  | 0.022        | 0.31         | 2.17         | 22.7         | 303.02       | 3027.70      |
| HINT          | ra    | 0.00007      | **0.00007**  | 0.00009      | 0.00012      | 0.00022      | 0.00041      | 0.00046      | 0.00047       | 0.00047     |
|               | rr    | 0.000007     | **0.000069** | 0.00039      | 0.0022       | 0.019        | 0.183        | 1.85         | 18.63         | 187.72      |
| CDEP          | ra    | 0.00007      | 0.00007      | 0.000072     | 0.00007      | **0.000097** | 0.00025      | 0.00075      | 0.002         | 0.0053      |
|               | rr    | 0.0000005    | 0.000001     | 0.0000027    | 0.00001      | **0.000036** | 0.00039      | 0.00477      | 0.057         | 0.74        |

* --> in general rule of thumb: the reg rate should be set such that ra and rr have the same order of magnitude. But there are cases in which it is beneficial to set it a little bit higher (CDEP)  


## Baseline performance
### MLP
Hyperparams: EPOCHS = 64, BATCH_SIZE = 256, LR = 0.001, optim=Adam, train_shuffle=True
**Note:** 5 runs with seeds [1,10,100,1000,10000]; in brackets regularizer_rate of XIL loss; keep in mind that train losses are not comparable because of different losses and different regularizer rates; HINT, RRRGradCam only work on cnn's
Run times on cpu Intel i5 4GB Ram

#### MNIST MLP Performance CEL:
train acc= 99.4% (±0.15%); test acc= 96.5% (±0.23%); train loss= 0.000076; test loss= 0.005986; run time= 142.25s (±9.9)

**Mean accuracies, losses:** 
|    Method     | train acc  | test acc  | train loss | test loss | run time |
| ------------- |:----------:| :--------:| :---------:| :--------:|:--------:|
| CrossEntropy  | 99.8% (±0.07)     | 59.2% (±1.05)    | 0.000034   | 0.007468  | 145s (±3.3)
| RRR (100)     | 99.2% (±0.13)     | 96.4% (±0.18)    | 0.000118   | 0.005995  | 222s (±3.1)
| RBR (1M)      | 97.4% (±2.26)     | 91.0% (±0.92)    | 0.000468   | 0.006256  | 431s (±12.2)
| CDEP (1K)     | 99.6% (±0.11)     | 60.7% (±0.81)    | 0.000063   | 0.007405  | 328s (±3.8)
| CE (60k)      | 99.6% (±0.10)     | 95.9% (±0.31)    | 0.000062   | 0.006004  | 229s (±2.8)

#### WR Metric
On models trained with seed=100
| model \ expl  | IG (Ross) mean   | IG (Ross) t=0.01   |Lime  mean         |
|-------------- |------------------|------------------  |-------------------|
| Vanilla       | 41.22% (±48.59)  | 44.05% (±48.8)     | 85.39 (±35.31)    |
| RRR (100)     | 0.0% (±0.0)      | 0.0% (±0.0)        | 31.99 (±46.64)    |
| RBR (1M)      | 21.30% (±40.26)  | 40.52% (±48)       | 50.28 (+-49.99)   |
| CDEP (1K)     | 36.70% (±47.12)  | 40.84% (±48)       | 80.39 (39.70)     |
| CE            | 21.74% (±16.99)  | 21.93% (±17)       | 44.75% (49.723)   |

t = 0.01 -> Binarize threshold: Every pixel activation > 0.01 => 1 (fully activated) - i.e. pixel is activated 1% -> very strict criterion.
Vanilla: median=0.001; mean=0.11770791066139936
RRR:     median=0.0; mean=0.07472601031959057
RBR:                 mean=0.07417608672771603
CDEP:                mean=0.0940777510959655
CE:                  mean=0.10083309492357075
##### IG
Vanilla:
MEANS = [0.11237539693750441, 0.11368475207537412, 0.11770791066139936, 0.11387983073703944, 0.11786100035756826]
WR scores= [41.495, 45.121875, 41.225, 41.96125, 43.634375]
MEAN WR = 42.6875
STD WR = 1.4772376564893013
No of ACT = [10000, 10000, 10000, 10000, 10000]
No of ACT = 10000.0

RRR:
MEANS = [0.07248291264995932, 0.07884679795727134, 0.07472601031959057, 0.072676512603648, 0.07859577116556465]
WR scores= [0.0, 0.0, 0.0, 0.0, 0.0]
MEAN WR = 0.0
STD WR = 0.0
No of ACT = [10000, 10000, 10000, 10000, 10000]
No of ACT = 10000.0

RBR:
MEANS = [0.07075958632715046, 0.06561658635102212, 0.07417608672771603, 0.0679817544259131, 0.08118881217390299]
WR scores= [15.9775, 12.720625, 21.303125, 19.38125, 17.46375]
MEAN WR = 17.36925
STD WR = 2.9352727034723713
No of ACT = [10000, 10000, 10000, 10000, 10000]
No of ACT = 10000.0

CDEP:
MEANS = [0.09708757237829269, 0.09668074799999594, 0.0940777510959655, 0.0873784378087148, 0.10512418218515814]
WR scores= [32.996249999999996, 36.411875, 36.706250000000004, 37.556250000000006, 34.038125]
MEAN WR = 35.54175
STD WR = 1.726953757704592
No of ACT = [10000, 10000, 10000, 10000, 10000]
No of ACT = 10000.0

CE:
MEANS = [0.09306998359560967, 0.10209390134438873, 0.10083309492357075, 0.09281144057512283, 0.09714552625417709]
WR scores= [20.51, 20.548125, 21.743750000000002, 21.313750000000002, 22.984375]
MEAN WR = 21.42
STD WR = 0.9112231648997956
No of ACT = [10000, 10000, 10000, 10000, 10000]
No of ACT = 10000.0

##### Lime
Vanilla: mean=0.12526322737149895
RRR: mean=0.11920070879235864
RBR: mean=0.11820786783359945
CDEP: mean=0.12443641773499549
CE: mean=0.12707239351589233

Note: setting other thresholds could yield different results; mean is dependend on the respective model, as it's calculated over all heatmaps of the model, leading to different thresholds for ecah model. This accounts for overall differences in the heatmaps per model (e.g. if one model has overall less activation than another and because of that a smaller activation in the confounder should have more influnce in determining how wrong the explanation is). On the other hand, setting a global threshold is independed of the model and can be used to check a threshold value which one classifies as activated if bigger. This ameroliates potential cases in which the differences bewteen mean thresholds of models are to big and prone to misleading conclusions. Checking both therefore yields more robust results.      

#### Heatmaps analysis
##### IG
* very often: If dark square then fully activation in all corners. In general if square has darker shade, more likely that confounder is activated in contrast to lighter shades (vice versa in IG). Why? Hypothesis.
* all the time: If focus on confounder then ALL corners are activated -> hypothesis: Because coner position of the squares are random in train set, prediction on test set in all corners
##### LIME
* manually inspection of 200 explanations
* Vanilla: In general matches the IG explanations (see WR scores); in contrast to IG only focuses on real corner position of the confounder. If square has lighter shade more likely to be activated than if dark shade ().    
* we noticed cases where Lime expl are completely different from IG (id=22); also cases where IG would classify Vanilla explanation as RAWR, but Lime would classify as RARR --> dangerous begvaior, as real life uase case of the XIL Framweork requires to intervene in RAWR case. Depends on the correctness of explainer methods. These results shows there needs to be more research done with regard to faithfullness of different explainer. 


### CNN
Hyperparams: EPOCHS = 64, BATCH_SIZE = 256, LR = 0.001, optim=Adam\
**Note:** 5 runs with seeds [1,10,100,1000,10000]; in brackets regularizer_rate of XIL loss; keep in mind that train losses are not comparable because of different losses and different regularizer rates; Run times on GPU NVIDIA Tesla T4 (compute capability: 7.5)

#### MNIST CNN Performance CEL:
train acc= 99.8% (±0.06); test acc= 98.8% (±0.11); train loss= 0.000044; test loss= 0.005892; run time= 87.67s (±0.9) 

**Mean accuracies, losses:** 
|    Method     | train acc  | test acc  | train loss | test loss | run time |
| ------------- |:----------:| :--------:| :---------:| :--------:|:--------:|
| CrossEntropy  | 99.9% (±0.04)     | 78.9% (±1.13)    | 0.000036   | 0.006694  | 95.69s (±0.8)
| RRR (10)      | 99.9% (±0.08)     | 98.8% (±0.13)    | 0.000023   | 0.005892  | 491.81s (±0.8)
| RRRGradCam (1)| 99.7% (±0.18)     | 97.4% (±0.70)    | 0.000176   | 0.005948  | 290.79s (±0.3)
| RBR (1M)      | 100 % (±0.00)     | 99.1% (±0.12)    | 0.000000   | 0.005881  | 1008.51s
| CDEP (1M)     | 99.3% (±0.03)     | 97.1% (±0.70)    | 0.000086   | 0.005969  | 450.81s (±0.5)
| HINT (100)    | 99.0% (±0.11)     | 86.0% (±1.41)    | 0.018215   | 0.006419  | 286.45s (±0.6)
| CE (60k)      | 99.9% (±0.02)     | 98.9% (±0.15)    | 0.000034   | 0.005887  | 177.73s (±0.5)

#### WR metric

On models trained with seed=100
| model \ expl  | IG (Ross) mean   | GradCAM (mean)     |Lime  mean         |
|-------------- |------------------|------------------  |-------------------|
| Vanilla       |  20.4%           |  36.0%             |  56.19%   |
| RRR (10)      |  0.0%            |  10.8%             |  33.89%   |
| RRR-G (1)     |  14.5%           |  2.1%              |  36.58%   |
| RBR (1M)      |  1.5%            |  8.7%              |  32.11%  |
| CDEP (1M)     |  17.0%           |  32.6%             |  40.08%    |
| HINT (100)    |  11.3%           |  8.3%              |  53.63%   |
| CE (60K)      |  5.1%            |  10.3%             |  36.04%  |

##### IG 
Vanilla:
MEANS= [0.04375756189096719, 0.05299534238558263, 0.05230600172057748, 0.04494304618956521, 0.048113826080970465]
WR scores= [26.1675, 20.515625, 20.394375, 19.251875, 29.080624999999998]
MEAN WR = 23.082
STD WR = 3.846642131456993
No of ACT = [10000, 10000, 10000, 10000, 10000]
No of ACT = 10000.0

RRR:
MEANS = [0.04891914581749588, 0.05148237575106323, 0.05341879708338529, 0.04890599369574338, 0.050078366393223404]
WR scores= [0.0, 0.0, 0.0, 0.0, 0.0]
MEAN WR = 0.0
STD WR = 0.0
No of ACT = [10000, 10000, 10000, 10000, 10000]
No of ACT = 10000.0

RRR-G:
MEANS = [0.0676166987966746, 0.07145727179087698, 0.07263356825523079, 0.0698850484117262, 0.07424128902051598]
WR scores= [11.861875, 11.940625, 14.459375, 7.856410641064106, 11.828750000000001]
MEAN WR = 11.589407128212823
STD WR = 2.1178695003729366
No of ACT = [10000, 10000, 10000, 9999, 10000]
No of ACT = 9999.8

RBR:
MEANS = [0.0582224872853607, 0.06297986234119161, 0.07027146466206759, 0.021286628254083916, 0.058908062394708395]
WR scores= [2.4575, 2.351875, 1.44125, 0.16375, 4.060625]
MEAN WR = 2.095
STD WR = 1.2820443269442754
No of ACT = [10000, 10000, 10000, 10000, 10000]
No of ACT = 10000.0

CDEP:
MEANS = [0.06994975720793009, 0.07491530140303075, 0.07750574043598026, 0.07168392772600055, 0.0714905912667513]
WR scores= [14.06625, 16.3325, 16.950000000000003, 12.956249999999999, 14.469999999999999]
MEAN WR = 14.955000000000002
STD WR = 1.4763220769872687
No of ACT = [10000, 10000, 10000, 10000, 10000]
No of ACT = 10000.0

HINT:
MEANS = [0.05464032325744629, 0.05707415423784405, 0.05874703137464821, 0.060666052101738754, 0.05892552099898458]
WR scores= [15.782499999999999, 13.109375, 11.129375, 6.411875, 12.823125]
MEAN WR = 11.851249999999999
STD WR = 3.1012916663867647
No of ACT = [10000, 10000, 10000, 10000, 10000]
No of ACT = 10000.0

CE:
MEANS = [0.057556263676285746, 0.06546326559949667, 0.06628613841086627, 0.05781883406564593, 0.05990915743485093]
WR scores= [9.3625, 7.538749999999999, 5.116875, 7.844375, 6.77]
MEAN WR = 7.3265
STD WR = 1.3892930193987159
No of ACT = [10000, 10000, 10000, 10000, 10000]
No of ACT = 10000.0

##### GradCAMs
Vanilla:
MEANS = [0.11065112382420991, 0.10544454380092856, 0.10645735242105421, 0.13984909048058014, 0.14334115154773117]
WR scores= [34.28004051604649, 35.300303809301234, 36.04783249416677, 46.368838028169016, 41.37623331398723]
MEAN WR = 38.67464963233415
STD WR = 4.562851230433056
No of ACT = [9379, 8558, 8143, 7952, 8615]
No of ACT = 8529.4

RRR:
MEANS = [0.07789883050968312, 0.07275663472250825, 0.06539483106228551, 0.06453581410894992, 0.07988520497970113]
WR scores= [15.59091420218149, 15.257996499045195, 10.821102187759625, 13.580713422007253, 11.111204576043068]
MEAN WR = 13.272386177407324
STD WR = 2.0046338993840815
No of ACT = [8893, 6284, 7222, 7443, 7430]
No of ACT = 7454.4

RRR-G:
MEANS = [0.06274084947136087, 0.0593810621424354, 0.06714394345805312, 0.0515736768593607, 0.08842762178428537]
WR scores= [1.8819971689615238, 0.710080413555428, 2.06383505835719, 0.612331081081081, 2.5024339003894243]
MEAN WR = 1.5541355244689294
STD WR = 0.7570972622316164
No of ACT = [7771, 8705, 9082, 7696, 9758]
No of ACT = 8602.4

RBR:
MEANS = [0.08039284477718005, 0.09340085327914617, 0.06156434839744991, 0.5518793935477734, 0.07727649217682227]
WR scores= [19.46870237955691, 18.393802799142605, 8.685897435897436, 15.064375, 14.151422764227641]
MEAN WR = 15.152840075764919
STD WR = 3.793745289510862
No of ACT = [8531, 7931, 7215, 10000, 8856]
No of ACT = 8506.6

CDEP:
MEANS = [0.22211234153868348, 0.17183399818030465, 0.3412173317219933, 0.35493331476673484, 0.2522478941667825]
WR scores= [19.168383757161525, 16.088024429102497, 32.55953572143286, 35.329375, 35.915625]
MEAN WR = 27.81218878153938
STD WR = 8.44846098670996
No of ACT = [9949, 9415, 9994, 10000, 10000]
No of ACT = 9871.6

HINT:
MEANS = [0.18115388926193118, 0.1816188109304756, 0.17977374961599707, 0.18241553208492697, 0.1801061299610883]
WR scores= [5.7775, 6.060625, 8.34875, 8.068125, 5.918749999999999]
MEAN WR = 6.83475
STD WR = 1.1286729347999804
No of ACT = [10000, 10000, 10000, 10000, 10000]
No of ACT = 10000.0

CE:
MEANS = [0.08150912839782716, 0.09113677647537508, 0.07139029491504845, 0.08884162972364171, 0.07560316270149679]
WR scores= [14.678174001011634, 17.71497831079357, 10.308001995154624, 17.855331558260428, 13.136963696369635]
MEAN WR = 14.738689912317977
STD WR = 2.8555886344429244
No of ACT = [7908, 7838, 7017, 7887, 7575]
No of ACT = 7645.0

##### Lime 
Vanilla=0.12472682695593684; RRR=0.12524728468824178; RRR-G=0.11859917477909476; RBR=0.12216663646288216; CDEP=0.1253164826164022; HINT=0.12351903840741142; CE=0.13121054584551603


#### Heatmaps
##### Gradcams
Manually inspecting 200 heatmaps
* in general tendency for large scattering of the activation in Vanilla,RRR,RBR,CE, sometimes with just one small area activated --> hypothesis: S-CNN does only have two convolutional layers and is not deep enough so that Gradcam can produce acccurate heatmaps. This is especially true for Models that are not trained with gradcam explainer except CDEP (Vanilla, RRR, RBR, CE). Those models have a larger number of test instances that could not attributed at all (Vanilla=18%, RRR=27%, RBR=27%, CE=30% in comparison to RRR-G=9%, CDEP=0.06% and HINT=0%).    
* disadvantage: In order to calculate gradcam heatmaps the last conv layer is used which is lower in dimension compared to orginial image. The heatmap needs to be upsampled to match the org images, which can lead to inaccuracies about the exact location/pixels which are activated --> potential to confuse the user
* Hint model is the only model that produces heatmaps that predominatly highlight the region of the numbers, so that sometimes its even possible to guess the underling number
* CDEP produces heatmaps that highlights large areas of the image (mean activation per pixel 34% vs Vanilla=10%, RRR=6%, RRR-G=7%, RBR=6%, Hint=18%, CE=7%)
* overall less activation in confouding areas (36% Vanilla) on all XIL methods, least in RRR-G and HINT (not surprising) see WR metric results
*   


## Switch XIL on: Correcting Clever-Hans behavior on pre-trained model.   
In this experiment we trained a simple cnn model for 50 epochs with cross entropy loss and after that we switched on the respective XIL loss and trained for another 50 epochs. We used the following setup:  
* Hyperparams: EPOCHS = 100, BATCH_SIZE = 256, LR = 0.001, optim=Adam, DISABLE_XIL_FOR_N_EPOCHS = 50, BASE_CRITERION = cross entropy  
* 5 runs with seeds [1,10,100,1000,10000]; in brackets regularizer_rate of XIL loss, besides CE (indicates the number of counterexamples n_instances)
* note: RBR with LR=0.001 would not train (10% train acc), we tried to reduce the regularizer rate [1M -> 1000, 10, 1] but training still crashed (reg=1 would train 30 epochs almost 100% train acc and > 95% test acc, but then crashed with the loss getting very huge. We tried reg=0.1 and the model trained to 99% train acc but no effect on the test acc, because the influence of rr is to small); We also tried a smaller LR=0.00001, then the model was able to train (but the CNN with CEL would get 97% acc on the test set, so the results after XIL is switched on are not meaningful). To compare the performance of RBR with the other methods and overcome the problem of exploding gradients we therefore clipped the rr_loss to a max value of 1.0 per batch.  
  

### MLP
Accuracy, loss **before switching XIL on** (same for all):  
train acc= 99.66% (±0.10); test acc= 58.18% (±1.27); train loss= 4.9e-05; test loss= 0.007503 
**Mean accuracies, losses:** 
|    Method     | train acc  | test acc  | train loss | test loss |
| ------------- |:----------:| :--------:| :---------:| :--------:|
| RRR (100)     | 99.5% (±0.31)     | 94.1% (±0.44)    | 0.000692   | 0.006152  |
| RBR (1M)      | 96.7% (±0.60)     | 68.7% (±1.55)    | 0.004869   | 0.007100  |
| CDEP (1M)     | 95.9% (±2.19)     | 56.7% (±2.03)    | 0.000593   | 0.007573  |
| CE (60k)      | 99.6% (±0.10)     | 95.5% (±0.34)    | 0.000050   | 0.006027  |

### CNN
Accuracy, loss **before switching XIL on** (same for all):  
train acc= 99.85% (±0.04); test acc= 77.75% (±1.57); train loss= 2.99e-05; test loss= 0.006735 

**After 50 epochs training with XIL loss**:  
|    Method     | train acc         | test acc     | train loss | test loss |
| ------------- |:-----------------:| :-----------:| :---------:| :--------:|
| RRR (100)     | 99.8% (±0.13)     | 98.1% (±0.34)| 0.000049   | 0.005930  |
| RBR (1M)      | 99.6% (±0.20)     | 87.2  (±2.55)| 0.004356   | 0.006365  |
| RRRGradCam (1)| 99.7% (±0.13)     | 95.0% (±2.56)| 0.000112   | 0.006048  |
| CDEP (1M)     | 99.6% (±0.39)     | 83.8% (±3.96)| 0.000114   | 0.006497  |
| HINT (1000)   | 97.2% (±0.55)     | 96.2% (±1.19)| 0.197442   | 0.006033  |
| CE (60k)      | 99.9% (±0.02)     | 98.9% (±0.17)| 0.000022   | 0.005888  |

## Feedback quality
This experiment aks the question of **How does the feedack quality influence the perfromance of the XIL methods?**  
We modeled four cases, which also include sanity checks. Listed are the following cases: Uncertain, incomplete, adversarial, wrong feedback?  

Details about the cases:  
* Uncertain feedback: Random masks: $A \in \text{randint}(\{0,1\})$
* Incomplete feedback: Subregion $S$ of the (un)important parts in the mask $A = 
    \begin{cases} 1, & \text{if}\ a_i \in S \\ 0, & \text{otherwise} \end{cases}$.  
    In our case we chose the bottom half of a square as $S$
* Adversarial feedback: All-one binary masks $A \in \{1\}$ 
* Wrong feedback: 5x3 rectangle region on top or bottom middle (opposite site to real confounder square). So if the confounder is in the top right corner the rectangle is in the bottom middle on der image border.  

We only evaluated XIL methods that increases the baseline performnace. 
--> rr_clipping=1.0 on random, adversarial for smoother training  in RBR

**MLP: Mean accuracies train and test:**  
|    Method     |$feedback->$| random  | wrong        | incomlete    |  adversarial |
| ------------- |:------|:------------:| :-----------:| :-----------:| :-----------:|
| RRR (100)     | train | 99.8%        | 99.6%        | 99.8%        | 99.8%        |
|               | test  | 59.2%        | 59.1%        | 60.1%        | 59.2%        |
| RBR (1M)      | train | 98.4%        | 99.2%        | 99.6%        | 98.7%        |
|               | test  | 64.1%        | 61.9%        | 64.1%        | 62.6%        |
| CE (60k)      | train | 96.4%        | 99.8%        | 99.8%        | 55.4%        |
|               | test  | 68.8%        | 58.8%        | 59.3%        | 56.5%        |

used rr_clipping=1.0 in random, adversarial

* Interpretation: Giving wrong feedback does not increase the performance of the above methods on the test set, which is an additional  indicator that the functionality of these methods is dependent on the use of correct feedback. Interestingly, if random feedback is provided the test performance increases slightly in all methods. We hypothesize that some of the random pixels fall into the confounding factor area which leads to the penalization of this area. This also would explain the better performance of RRR with adversarial feedback. Incomplete feedback does not improve test performance. This can be attributed to the structure of an MLP, where each input pixel is conected to output neurons, so the other pixels of the confunding area still propagate their information through the network influencing the output neurons (Should not be the case for an CNN). This could be because the model is still able to focus on the top half of the confounder which also provides the misleading information which gets learned during the training.
  
**CNN: Mean accuracies train and test:**
|    Method     |$feedback->$| random  | wrong        | incomlete    |  adversarial | correct      |
| ------------- |:------|:------------:| :-----------:| :-----------:| :-----------:|:------------:|
| RRR (100)     | train | 89.9% (±0.57)| 99.9% (±0.06)| 99.9% (±0.08)| 88.5% (±0.69)| 99.9% (±0.08)|
|               | test  | 92.3% (±2.61)| 84.3% (±3.13)| 98.6% (±0.28)| 91.9% (±1.81)| 98.8% (±0.13)|
| RBR (1M)      | train | 99.5% (±0.22)| 100%  (±0.00)| 99.2% (±1.58)| 99.6% (±0.20)| 100 % (±0.00)|     
|               | test  | 90.1% (±0.48)| 87.4% (±1.55)| 97.1% (±0.71)| 90.5% (±2.46)| 99.1% (±0.12)|
| RRRGradCAM (1)| train | 55.5% (±36.3)| 99.7% (±0.22)| 99.8% (±0.03)| 41.4% (±36.9)| 99.7% (±0.18)|
|               | test  | 55.4% (±36.0)| 74.4% (±3.15)| 93.9% (±1.93)| 40.6% (±35.8)| 97.4% (±0.70)|
| HINT (1k)     | train | 27.6% (±32.7)| 71.9% (±30.6)| 97.2% (±0.16)| 11.2% (±0.00)| 97.6% (±0.25)|      
|               | test  | 27.9% (±27.9)| 69.9% (±29.4)| 96.8% (±0.11)| 11.3% (±0.00)| 96.6% (±0.39)|
| CDEP (1M)     | train | 95.6% (±7.00)| 99.3% (±0.28)| 99.3% (±0.18)| 99.5% (±0.18)| 99.3% (±0.03)|
|               | test  | 95.1% (±1.68)| 93.0% (±2.36)| 96.6% (±1.69)| 93.8% (±1.92)| 97.1% (±0.70)|
| CE (60k)      | train | 99.5% (±0.09)| 100%  (±0.02)| 100%  (±0.01)| 55.6% (±0.03)| 99.9% (±0.02)| 
|               | test  | 92.1% (±1.98)| 78.9% (±2.05)| 86.2% (±1.20)| 79.2% (±0.95)| 98.9% (±0.15)|
  
--> **Interpretation:**
* **Random**: Both methods using GradCAM (RRRGradCAM, HINT) are not able to train anymore, because the rr loss is to huge and successfully confuses the model completely. We attribute the performance increase of RRR and CDEP in the test set to the lower train accuracy, meaning random feedback prevents the model to overfit on the confounder. This finding is supported by the test accs of RBR and CE. Both methods reach a high train acc (>99%) - increasing the chances of overfitting - while the test acc is also >90%. Compared to the baseline test acc (79%) this is an increase of approx 10%. We hypothesize that some random pixels fall into the confounder area and therefore preventing the model from focussing heavily on this specific spot.          
* **Wrong**: Normally this should not increase the test acc as the feedback masks are placed on the middle top/bottom border and therefore do not penalize (reward) the confounder. The model could completely focus on the confounder leading to the baseline test acc of around 79%, which is confimred only by the CE and RRRGradCAM method. Interestingly, the test acc is slightly higher with RRR, and RBR than the baseline (5%, 7%), but still a lot smaller than with correct feedback (-14% and -11.7%). Currently it's not clear what causes the slight improvement. CDEP also has 14% higher test acc than the baseline for wrong feedback, we follow that CDEP is independent from the feedback making it unsafe to use. As expected, rewarding the right reason with wrong feedback masks (HINT) leads to a low train and test accuracy.      
* **Incomplete**: In contrast to the MLP, all of the methods improve the test set performance compared to the baseline, reaching near perfect test acc. We follow that providing incomplete feedback gives the models enough information to overcome the confoundinf factor. Only the RRRGradCAM and CE method perform worse when compared to correct/full feedback (-3.5%, -12.7%), but still significatly better than without feedback.    
* **Adversarial**: RRRGradCAM, HINT, CE are not able to reach a good train acc, they get confused by the adversarial feedback. RRR and RBR are able to train, but only RBR reaches a high train accuracy. Both methdos have a higher test acc than the baseline. We hypothesize that in masking the whole image (including the confounding area) it somehow guides the model to not focus on specific spots but 'spread' its focus across the whole image restricting overfitting. 

## Interaction efficiancy
This experiment tests the efficiancy of a XIL method, by manipulating the number of available ground-truth feedback explanations (n_expl). We want to observe how the test accuracy develops when we increase the number of available feedback explanations. This should be an indicator on how many explanatory interactions the respective XIL methods need to overcome the focusing on the confounding factor.  
* we tested the following number of explanations: n_expl [25, 50, 100, 200, 400, 800, 1600, 5000, 10000, 20000]
* we cross validated each n_expl with 5 different seeds [1,10,100,1000,10000]  
* hyperparams: EPOCHS = 64, BATCH_SIZE = 256, LR = 0.001, optim=Adam  
* CE in brackets is the number of n_counterexamples per instance (2 meaning that for one instances 2 counterexamples were added to the train set); we used the ce_strategy 'random' 

### MLP
CEL: test_acc= 59.2% (±1.05)
**Mean accuracies train and test:**
|    Method     |       | 25           | 50           |        100   |       200    |          400 |          800 |         1600 |         5000 |        10000 |       20000  | 60000        |
| ------------- |:------|:------------:| :-----------:| :-----------:| :-----------:|:------------:|:------------:| :-----------:| :-----------:| :-----------:|:------------:|:-------------|
| RRR (100)     | train | 99.3% (±0.27)| 99.4% (±0.19)| 99.4% (±0.23)| 99.4% (±0.12)| 99.4% (±0.06)| 99.5% (±0.16)| 99.6% (±0.15)| 99.3% (±0.06)| 99.4% (±0.16)| 99.3% (±0.13)| 99.2% (±0.13)| 
|               | test  | 87.0% (±2.17)| 93.6% (±0.70)| 95.9% (±0.55)| 96.6% (±0.17)| 96.3% (±0.22)| 96.6% (±0.25)| 96.7% (±0.25)| 96.7% (±0.14)| 96.7% (±0.23)| 96.7% (±0.11)| 96.4% (±0.18)|
| RBR (1M)      | train | 99.7% (±0.06)| ??  % (±????)| 99.4% (±0.47)| 99.1% (±0.55)| 98.4% (±0.51)| 96.2% (±1.02)| 94.9% (±0.85)| 95.5% (±2.35)| 97.5% (±0.38)| 97.9% (±0.96)| 97.4% (±2.26)| 
|               | test  | 60.1% (±0.59)| ??  % (±????)| 65.1% (±0.55)| 67.1% (±2.75)| 70.0% (±2.43)| 73.3% (±2.70)| 82.5% (±2.04)| 89.6% (±3.50)| 89.4% (±2.73)| 88.2% (±1.93)| 91.0% (±0.92)|
| CE (n=1)      | train | 99.8% (±0.07)| 99.6% (±0.10)| 99.7% (±0.12)| 99.7% (±0.05)| 99.7% (±0.06)| 99.7% (±0.04)| 99.6% (±0.09)| 99.6% (±0.09)| 99.6% (±0.07)| 99.5% (±0.05)| 99.9% (±0.01)|
|               | test  | 58.7% (±0.86)| 59.9% (±0.76)| 62.1% (±0.79)| 64.0% (±0.64)| 66.2% (±0.50)| 70.2% (±0.92)| 73.1% (±1.42)| 80.5% (±1.68)| 86.3% (±1.05)| 91.9% (±0.87)| 95.9% (±0.31)|
| CE (n=2)      | train | 99.7% (±0.12)| 99.7% (±0.09)| 99.7% (±0.13)| 99.7% (±0.09)| 99.7% (±0.07)| 99.7% (±0.10)| 99.7% (±0.07)| 99.6% (±0.09)| 99.7% (±0.08)| 99.6% (±0.02)| |
|               | test  | 59.7% (±1.40)| 61.4% (±0.82)| 62.4% (±0.73)| 65.4% (±1.66)| 67.8% (±1.36)| 72.3% (±1.06)| 76.3% (±1.76)| 83.6% (±1.43)| 90.0% (±1.55)| 93.1% (±0.59)| |
| CE (n=3)      | train | 99.7% (±0.07)| 99.7% (±0.08)| 99.7% (±0.09)| 99.7% (±0.03)| 99.7% (±0.09)| 99.6% (±0.08)| 99.7% (±0.05)| 99.7% (±0.05)| 99.6% (±0.05)| 99.7% (±0.05)| |
|               | test  | 59.8% (±1.48)| 61.2% (±0.97)| 64.2% (±1.25)| 65.8% (±0.66)| 68.5% (±0.58)| 72.5% (±1.18)| 78.0% (±1.68)| 86.4% (±0.83)| 90.7% (±0.36)| 94.2% (±0.28)| |
| CDEP (100)    | train | 99.2% (±0.26)| 99.3% (±0.39)| 99.5% (±0.10)| 99.5% (±0.16)| 99.4% (±0.09)| 99.2% (±0.57)| 99.4% (±0.45)| 99.5% (±0.28)| 99.5% (±0.13)| 99.6% (±0.17)| 99.6% (±0.11)| 
|               | test  | 64.5% (±2.95)| 62.3% (±0.83)| 61.1% (±3.07)| 63.2% (±0.77)| 63.6% (±2.99)| 61.6% (±1.53)| 60.2% (±2.00)| 61.0% (±1.51)| 60.4% (±0.91)| 60.4% (±1.42)| 60.7% (±0.81)|

* RBR: Because of the large reg rate the training process was quiet unstable and the model would sometimes not train (train acc), because the differences between a batch with XIL examples and without was to big. We therefore clipped the rr loss to a max of 1.0 per batch. 

### CNN
CEL: test_acc= 76.9% (±2.74)

**Mean accuracies train and test:** 
|    Method     |       | 25           | 50           |        100   |       200    |          400 |          800 |         1600 |         5000 |        10000 |       20000  |     60000   |
| ------------- |:------|:------------:| :-----------:| :-----------:| :-----------:|:------------:|:------------:| :-----------:| :-----------:| :-----------:|:------------:|:-----------:|
| RRR (100)     | train | 99.9% (±0.08)| 99.9% (±0.04)| 99.9% (±0.07)| 99.9% (±0.04)| 99.9% (±0.09)| 99.9% (±0.02)| 99.9% (±0.04)| 99.9% (±0.06)| 99.8% (±0.04)| 99.9% (±0.03)|99.9% (±0.08)|
|               | test  | 98.9% (±0.22)| 99.0% (±0.10)| 98.9% (±0.21)| 98.9% (±0.15)| 98.9% (±0.13)| 98.9% (±0.32)| 98.9% (±0.02)| 99.0% (±0.19)| 98.9% (±0.16)| 98.9% (±0.07)|98.8% (±0.13)|

| RBR (1M)      | train |100.0% (±0.00)| 100% (±0.00) | 100%  (±0.00)| 100%  (±0.06)| 100%  (±0.00)| 99.9% (±0.21)| 99.3% (±0.59)| 100%  (±0.00)| 98.6% (±2.76)| 100%  (±0.02)|100 % (±0.00)|
|               | test  | 89.7% (±4.13)| 92.7% (±2.50)| 96.6% (±1.53)| 93.7% (±3.29)| 97.6% (±1.16)| 98.7% (±0.11)| 98.6% (±0.36)| 99.0% (±0.07)| 98.5% (±1.04)| 99.0% (±0.27)|99.1% (±0.12)| 

| CE (n=1)      | train | 99.9% (±0.03)| 99.9% (±0.03)| 99.9% (±0.01)| 99.9% (±0.06)| 99.9% (±0.04)| 99.9% (±0.03)| 99.9% (±0.03)| 99.9% (±0.04)| 99.9% (±0.03)| 99.9% (±0.02)|99.9% (±0.02)|
|               | test  | 80.7% (±1.75)| 80.0% (±1.88)| 82.5% (±1.64)| 82.8% (±1.66)| 87.8% (±1.27)| 90.3% (±0.54)| 93.9% (±1.29)| 96.3% (±0.44)| 97.4% (±0.33)| 98.4% (±0.11)|98.9% (±0.15)|

| RRRGradCAM (1)| train | 99.9% (±0.02)| 99.9% (±0.03)| 99.6% (±0.06)| 99.9% (±0.04)| 99.9% (±0.03)| 99.9% (±0.04)| 99.8% (±0.06)| 99.8% (±0.10)| 99.8% (±0.08)| 99.8% (±0.12)|99.7% (±0.18)|
|               | test  | 83.5% (±1.02)| 84.8% (±2.43)| 89.2% (±2.40)| 89.7% (±1.69)| 91.0% (±2.09)| 93.5% (±1.57)| 92.4% (±2.67)| 96.0% (±1.10)| 96.3% (±2.21)| 97.1% (±0.82)|97.4% (±0.70)|

| HINT (1000)   | train | 98.7% (±0.11)| 98.5% (±0.19)| 98.2% (±0.29)| 98.1% (±0.22)| 98.1% (±0.26)| 98.2% (±0.03)| 98.1% (±0.15)| 97.9% (±0.21)| 97.9% (±0.10)| 97.8% (±0.14)|97.6% (±0.25)|
|               | test  | 96.9% (±0.28)| 96.9% (±0.36)| 96.0% (±0.86)| 96.9% (±0.60)| 97.0% (±0.20)| 97.1% (±0.59)| 97.3% (±0.38)| 96.9% (±0.58)| 97.2% (±0.30)| 96.6% (±0.24)|96.6% (±0.39)|

| CDEP (1M)     | train | 99.5% (±0.35)| 97.3% (±4.69)| 99.5% (±0.24)| 98.8% (±0.98)| 99.2% (±0.47)| 98.1% (±2.21)| 94.8% (±8.97)| 99.3% (±0.24)| 99.2% (±0.24)| 99.2% (±0.30)|99.3% (±0.03)|
|               | test  | 86.7% (±6.73)| 87.2% (±3.02)| 88.8% (±5.78)| 94.2% (±1.98)| 92.8% (±2.33)| 95.8% (±1.43)| 93.3% (±3.01)| 97.7% (±0.45)| 97.0% (±1.10)| 97.1% (±0.41)|97.1% (±0.70)|
  

* RBR: Because of the large reg rate the training process was quiet unstable and the model would sometimes not train (train acc), because the differences between a batch with XIL examples and without was to big. We therefore clipped the rr loss to a max of 1.0 per batch. 
* note: Baseline train acc 97% --> test acc 97% (without XIL); 
* HINT: only a few example are enough to overcome confounders (the rr loss rate is higher than the rule of thumb). We hypothesize if the rr loss is added for only a few examples and is bigger than the ra loss then the model is punished for focussing only a few times on the confounder. Devils Advocat --> This could also only prevent the model from reaching a high train acc and therefore (as a high test acc is also achieved by the 'no- XIL-model' when stopped early at 97/98 train acc) the test acc is so high; it only prevents overfitting on the confounder. We should check some visualizations to check that. Sanity check --> One could add an equal sized loss term than the rr_loss BUT independently of the explanation from the model and the user annotation mask, we only add it n_expl times. If the model still reaches 97% test acc while having train acc around 97/98% then we could follow that HINT actually has no real effect.    

# Decoy Fashion Mnist

## Regularizer rate stability
### CNN
CEL train= 99.5%; test= 58.3%  
**Mean accuracies train and test:** 
|    Method     |$\lambda_1$| 0.01     | 0.1          |        1     |       10     |      100     |    1k        |    10k       |      100k    |        1M    |
| ------------- |:------|:------------:| :-----------:| :-----------:| :-----------:|:------------:|:------------:| :-----------:| :-----------:| :-----------:|
| RRR           | train | 99.3% (±0.27)| 99.2% (±0.22)| 98.8% (±0.24)| 98.9% (±0.34)| 98.7% (±0.32)| 98.4% (±0.16)| 96.4% (±0.62)| 93.4% (±0.51)| 85.7% (±3.06)|
|               | test  | 76.7% (±0.87)| 85.2% (±1.03)| 89.1% (±0.18)| 89.0% (±0.42)| 89.4% (±0.40)| 89.1% (±0.34)| 89.5% (±0.20)| 89.7% (±0.37)| 85.5% (±2.35)|
| RBR           | train | 99.5% (±0.16)| 99.4% (±0.16)| 99.3% (±0.11)| 99.0% (±0.57)| 99.3% (±0.23)| 99.2% (±0.75)| 97.7% (±1.57)| 96.1% (±4.89)| 76.6% (±33.5)|
|               | test  | 59.3% (±1.55)| 61.0% (±1.75)| 63.2% (±1.24)| 63.5% (±2.22)| 67.2% (±1.37)| 70.6% (±1.60)| 74.7% (±1.78)| 79.0% (±1.04)| 64.5% (±28.1)|
| RRRGradCAM    | train | 99.5% (±0.07)| 98.9% (±0.66)| 93.9% (±2.03)| 56.2% (±30.1)| 44.3% (±31.0)| 67.1% (±19.8)| 50.9% (±33.6)| 61.9% (±26.9)| 54.1% (±29.5)|
|               | test  | 63.1% (±0.90)| 62.2% (±1.73)| 71.1% (±3.66)| 54.2% (±28.1)| 41.7% (±32.2)| 64.9% (±18.3)| 50.3% (±32.9)| 61.5% (±26.2)| 52.1% (±27.4)|
| HINT          | train | ???% (±?????)| 99.4% (±0.08)| 99.0% (±0.12)| 94.5% (±0.55)| 54.8% (±36.9)| 21.7% (±23.7)| 32.7% (±28.0)| 9.80% (±0.09)| 23.3% (±0.14)|
|               | test  | ???% (±?????)| 58.8% (±3.04)| 58.2% (±1.88)| 59.6% (±1.81)| 46.7% (±30.0)| 21.9% (±23.8)| 33.3% (±28.6)| 10.0% (±0.00)| 23.1% (±27.0)|
| CDEP          | train | 99.5% (±0.22)| 99.3% (±0.21)| 99.5% (±0.15)| 99.5% (±0.12)| 99.3% (±0.06)| 99.1% (±0.18)| 98.2% (±1.74)| 97.7% (±1.49)| 95.6% (±26.2)|
|               | test  | 59.2% (±1.82)| 58.4% (±2.07)| 58.4% (±1.95)| 56.7% (±2.42)| 58.8% (±2.71)| 57.6% (±2.10)| 57.8% (±2.55)| 59.2% (±1.45)| 65.5% (±2.63)|

**CNN RA vs RR loss:**
Mean (avg over epochs) right answer loss vs right reason loss...
|    Method     |$\lambda_1$| 0.01     | 0.1          |        1     |       10     |      100     |    1k        |    10k       |      100k    |        1M    |
| ------------- |:------|:------------:| :-----------:| :-----------:| :-----------:|:------------:|:------------:| :-----------:| :-----------:| :-----------:|
| RRR           | ra    |  0.00023     | 0.0003       | 0.0004       | 0.00046      | 0.00053      | **0.00069**  | 0.0014       | 0.004        | 0.015        |
|               | rr    |  0.0000051   | 0.000075     | 0.000079     | 0.000055     | 0.00006      | **0.00015**  | 0.0010       | 0.0093       | 0.091        |
| RBR           | ra    | 0.00021      | 0.00021      | 0.00021      | 0.00023      | 0.00025      | 0.00027      | 0.00032      | 0.00046      | 349.235      |
|               | rr    | 0.0000012    | 0.0000029    | 0.0000054    | 0.0000089    | 0.000014     | 0.000026     | 0.000024     | 0.000051     | 1750.117     |
| RRRGradCAM    | ra    | 0.00025      | **0.00035**  | 0.00014      | 0.0046       | 0.0047       | 0.0037       | 0.0051       | 0.0041       | 0.0039       |
|               | rr    | 0.000077     | **0.00023**  | 0.00354      | 0.0655       | 0.86         | 10.67        | 97.80        | 985.83       | 8893.38      |
| HINT          | ra    | ??           | **0.00021**  | 0.00028      | 0.00081      | 0.0040       | 0.0075       | 0.0067       | 0.0086       | 0.0067       |
|               | rr    | ??           | **0.00015**  | 0.00088      | 0.0045       | 0.069        | 1.35         | 10.97        | 163.27       | 1157.2       |
| CDEP          | ra    | 0.00022      | 0.00021      | 0.000072     | 0.00022      | 0.0026       | **0.00049**  | 0.0012       | 0.0028       | 0.0049       |
|               | rr    | 0.0000005    | 0.000001     | 0.0000027    | 0.00001      | 0.00003      | **0.00033**  | 0.0035       | 0.041        | 0.500        |
  

* --> one should aim at setting the reg rate such that rr and ra loss are in the same order of magnitude (balanced). If the balance is too unequal, i.e. the rr loss much higher than the ra loss or vice versa, the model does not converge (rr > ra) or the confounders are not overcome (ra > rr).   
* CDEP does not work, despite setting the reg rate in the same order of magnitude.   
* in case of FashionMNIST: Both methods which use GradCam as the explainer method (RRRGradCAM, HINT) does not work (RRRGradCAM only improves the baseline test acc by 4 %). We hypothesize that the conv model is to small, such that the gradCAMs are not expressive enough and that the images in FashionMNIST take up large areas of the small 28x28 images - making it more difficult than the DecoyMNIST. We can also observe a slightly worse performance on the decoyMNIST, again because of the shallow conv model.   
* RBR trains quite instable, because one needs a really high reg rate to balance ra and rr, which in consequence leads to big differences in the loss update per batch. Remedy through clipping of rr loss (setting max value) or other smoothing operations that generate a better balance between ra and rr.
* In general one could optimize the methods/xil training by introducing a 'balancer' which monitors the development of the two losses and if necessary intervenes. Such a balancer should leave enough room for natural occuring differences in the losses but also compress both losses in some 'equal' magnitude of order, enabling the model to learn its objectives steadily - focus on right prediction versus focus of right reason while.      


## Baseline performance
Hyperparams: EPOCHS = 64, BATCH_SIZE = 256, LR = 0.001, optim=Adam\
**Note:** 5 runs with seeds [1,10,100,1000,10000]; in brackets regularizer_rate of XIL loss; keep in mind that train losses are not comparable because of different losses and different regularizer rates; Run times on GPU NVIDIA Tesla T4 (compute capability: 7.5)
### CNN
#### FashionMNIST Performance CEL:
 train acc= 98.7% (±0.26); test acc= 89.1% (±0.45); train loss= 0.000175; test loss= 0.006280; run time= 88.13s (±0.8) 

**Mean accuracies, losses:** 
|    Method     | train acc  | test acc  | train loss | test loss | run time |
| ------------- |:----------:| :--------:| :---------:| :--------:|:--------:|
| CrossEntropy  | 99.5% (±0.17)     | 58.3% (±2.47)    | 0.000078   | 0.007494  | 95.11s (±0.2) 
| RRR (100)     | 98.7% (±0.32)     | 89.4% (±0.40)    | 0.000195   | 0.006269  | 489.04s (±0.1)
| RBR (1M)      | 96.6% (±2.29)     | 83.4% (±0.80)    | 0.000264   | 0.006498  | 1205.46s (±3.9)
| RRRGradCam (0.1)|98.9% (±0.66)    | 62.2% (±1.73)    | 0.000304   | 0.007339  | 283.69s (±0.3)
| CDEP (1k)     | 99.1% (±0.18)     | 57.6% (±2.10)    | 0.000109   | 0.007521  | 445.03s (±3.0)
| HINT (1)     | 99.0%% (±0.12)    | 58.2% (±1.88)    | 0.001033   | 0.007496  | 340.8 (±2.5)
| CE (60k)      | 99.1% (±0.15)     | 87.7% (±0.79)    | 0.000146   | 0.006334  | 179.00s (±0.3)


#### WR scores

##### IG 
Means -> WR scores:
Vanilla=[0.07095232442840933, 0.06874594752695412, 0.06597223592344671, 0.06382668090965599, 0.06708661979399622] -> WR Scores=[25.460624999999997, 27.406875000000003, 22.339375, 26.60125, 23.189375000000002]
RRR = [0.05561773428656161, 0.06006174433343112, 0.0587343389775604, 0.058236598480306566, 0.059145968296192585] -> WR scores= [0.0, 0.0, 0.0, 0.0, 0.0]
RRR-G = [0.06492713042870164, 0.06455666799023747, 0.06828391736671328, 0.058975282072089616, 0.06822921836189925] -> WR scores=[18.61, 19.548750000000002, 18.439375, 18.099999999999998, 20.31125]
RBR =  [0.062122518760710954, 0.0692765873413533, 0.061487428432703016, 0.020039455067692325, 0.06338129945099354] -> WR = [6.004375, 6.51375, 3.8600000000000003, 5.46125, 8.04]
CDEP = [0.06691159685757012, 0.06770901541281492, 0.0689377890041098, 0.06481022639721631, 0.06826919635981321] -> WR = [25.255625, 21.94875, 23.515625, 21.30125, 24.84875] 
HINT = [0.06414111610986292, 0.0727066581485793, 0.0703926275216043, 0.06304306342229248, 0.06776081568077207] -> WR = [28.853125000000002, 31.468125, 23.520625, 29.669375, 33.331875]
CE = [0.06589774770047516, 0.07239909741375596, 0.0675750293167308, 0.06385448772180825, 0.07045580711588263] -> WR = [8.815000000000001, 7.754375, 8.155625, 7.8931249999999995, 7.706250000000001]

##### Gradcam
Means -> WR:
Vanilla = 
[0.14814270346021155, 0.11969024433503982, 0.12285725492021947, 0.10520659285750329, 0.13290902868809595] -> WR = [33.29860737713733, 35.38679559853284, 34.729396235078056, 33.34575151940159, 37.06655632732798] -> No of ACT = [9299, 8997, 8712, 8556, 9214]

RRR:
MEANS= [0.12787644010690907, 0.10831532266880693, 0.1143916503430694, 0.1177163612785263, 0.12110525978333457]
WR scores= [27.488061502938706, 19.21925476216999, 19.087369319394067, 27.60316184351554, 27.387559933291637]
MEAN WR = 24.157081472261986
STD WR = 4.086343179639156
No of ACT = [9528, 8977, 9374, 9330, 9594]
No of ACT = 9360.6

RRR-G:
MEANS= [0.10399267372968914, 0.10921981058507937, 0.11291531096519425, 0.10665724637945212, 0.12677831436550047]
WR scores= [8.339952343129468, 8.948371448371448, 6.687513867317506, 8.171090273363001, 9.975268513284341]
MEAN WR = 8.424439289093153
STD WR = 1.074040025208714
No of ACT = [8813, 8658, 9014, 9438, 8845]
No of ACT = 8953.6

RBR:
MEANS= [0.07962622387712187, 0.07899230030832455, 0.07840207255882449, 0.5979459245488048, 0.07331256136052228]
WR scores= [13.980112333791839, 16.53843851035804, 11.303398058252426, 24.981875000000002, 13.195010479739173]
MEAN WR = 15.999766876428296
STD WR = 4.795205448475146
No of ACT = [8724, 8351, 7725, 10000, 8588]
No of ACT = 8677.6

CDEP:
MEANS= [0.07929177906305573, 740417333725, 0.07721247341793422, 0.08851230382021728, 0.08538539656159631]
WR scores= [31.136573089465475, 28.389205662603224, 28.98614913834756, 32.25422645262111, 33.35888085710598]
MEAN WR = 30.82500704002867
STD WR = 1.8907556577308147
No of ACT = [7053, 5086, 6209, 7039, 7747]
No of ACT = 6626.8

Hint:
MEANS= [0.2321536925014724, 0.2858053820739419, 0.22329410657871188, 0.2832782873423966, 0.24926317145668694]
WR scores= [28.031834259727134, 24.99937355918613, 25.707618567103935, 26.89678485576923, 33.20837512537613]
MEAN WR = 27.76879727343251
STD WR = 2.9098717046813607
No of ACT = [9895, 9977, 9910, 9984, 9970]
No of ACT = 9947.2

CE:
MEANS= [0.10801507634546034, 0.10089686405232987, 0.10354602682537958, 0.10825512684948514, 0.10732183335554984]
WR scores= [25.154847396768403, 23.48988600804649, 24.05758270350638, 25.79910306215722, 23.68193420306296]
MEAN WR = 24.43667067470829
STD WR = 0.8923828607774038
No of ACT = [8355, 8948, 8071, 8752, 8815]
No of ACT = 8588.2

##### LIME
Vanilla: 
mean= 0.3482891964267987 -> WR: Number of actScores= 9999
Activation AVG per instance = 57.41574157415742
STD = 49.447009787299706
Activation ABS sum = 5741.0
Number of complete zero attr= 1

RRR:
mean=0.3721581702307798
Number of actScores= 10000
Activation AVG per instance = 27.02
STD = 44.406301354650104
Activation ABS sum = 2702.0
Number of complete zero attr= 0

RRR-G:
mean=0.3447386036963668
Number of actScores= 10000
Activation AVG per instance = 53.790000000000006
STD = 49.85615207775266
Activation ABS sum = 5379.0
Number of complete zero attr= 0

RBR:
mean = 0.3690440222498657
Number of actScores= 9998
Activation AVG per instance = 32.796559311862374
STD = 46.94722173345012
Activation ABS sum = 3279.0
Number of complete zero attr= 2

CDEP:
mean = 0.35712102412961777
Number of actScores= 9999
Activation AVG per instance = 57.515751575157516
STD = 49.431907491624436
Activation ABS sum = 5751.0
Number of complete zero attr= 1

HINT:
mean = 0.3579423919811845
Number of actScores= 10000
Activation AVG per instance = 57.16
STD = 49.48468854100226
Activation ABS sum = 5716.0
Number of complete zero attr= 0

CE:
mean= 0.38894003364893737
Number of actScores= 9998
Activation AVG per instance = 31.18623724744949
STD = 46.32539617845425
Activation ABS sum = 3118.0
Number of complete zero attr= 2

#### Heatmaps

Again we randomly sample 200 images from the test set to manually inspect the visualized explanations generated with IG and LIME. We do not inspect GradCAM visualizations, although we list the WR score quantifcation.

* Lime: In general -> One can almost everytime clearly determine the clothing based on the highlighted regions. The vanilla model shows almost in every image activation on the confounder, in many cases this is the region with maximum activation. This indicates that the vanilla model indeed uses the squres as informative features and is supported by the WR metric result (57% avg activation) and the poor test accurcay. Noticeable is the tendency that squares with a lighter shade get activated more often than the darker squares - we found the same on the decoyMNIST dataset. The RRR heatmaps show a cleary reduced influnece of the squares and often the focus is only on the clothing (supported by the WR score-> avg over all test images: has 27% activation of the confounding area). Similarly, the RBR and CE heatmaps also show considerable less activation in the corner squeres than the vanilla model. These findings correlate with the baseline accurcay scores on the test set. This also applies to the heatmaps of CDEP and the gradcam-based methods of RRR-G and HINT, which all show little change to the vanilla heatmpas. 

* IG: In general -> heatmaps are very scatterd as activated pixels spread over image. Activated pixels most commonly (as common in gradient methods) are most activated at the borders of the clothing pieces, although its not possible to conclude back to the orginal image. The vanilla heatmaps confirm that the model very frequently focuses on the confouding area, especially the border pixels and adjoing pixel around the square). In contrast to Lime, the activation is more spread acroos the image. Similar to previous findings lighter squares are more frequently activated as darker ones, which is not surprising as a darker schade is more similar to the standard black background of the fashionMNIST images (posess less possible informative value). Analyzing the RRR heatmaps we can see semi-circular cutouts in the activation on all four corners, including the one containing the confounder. This indicates that RRR successfully removes the focus on the confounder. We can see a smiliar pattern in the RBR and CE heatmaps, although the non activated cutouts are smaller and sometimes contain few scatterd weakly activated pixels. By contrast CDEP, RRR-G and HINT do not show these cutoffs and more or less reasemble the vanilla heatmaps having likewise activation especially on border pixels of the square.         

* GradCAM: In general -> partly coincidental; very instable and relativlely great amount of heatmaps that could not be attributed (Vanilla=10\%, RRR=6\%, RBR=13\%, CDEP=34\%, CE=14\%, RRR-G=10\%, HINT=0.5\%); imprecise because of upscaling. Therefore we classify WR Gradcam results as not reliable and do not take these results into account. -> S-CNN to shallow to produce reliable Gradcam attributions. This would also partly explain the poor performance of RRR-G, HINT which use a Gradcam base loss augmentation. Hypothesis -> HINT right reason masks are not optimal, as they could also probably contrain the models capability to find correlations. Combined with the more complex images this makes it tough for the HINT-model. Vanilla heatmaps do not show a clear correlation between the confounder and a bigger activation.    

In summary, the qualitative analysis of the visualizations as well as the quantification of WR across the different explainer methods confirm the baseline accuracies. Furthermore, it is evident that a XIL method is evaluated best on the particular utilized explainer method, as the results of the WR metric suggest.   




## Switch XIL on   
In this experiment we trained a simple cnn model for 50 epochs with cross entropy loss and after that we switched on the respective XIL loss and trained for another 50 epochs. We used the following setup:  
* Hyperparams: EPOCHS = 100, BATCH_SIZE = 256, LR = 0.001, optim=Adam, DISABLE_XIL_FOR_N_EPOCHS = 50, BASE_CRITERION = cross entropy  
* 5 runs with seeds [1,10,100,1000,10000]; in brackets regularizer_rate of XIL loss, besides CE (indicates the number of counterexamples n_instances)
* note: we clipped the max rr loss in RBR to 1.0 per batch, otherwise the loss gets to high to train with the used reg rate.   
* we only trained with methods that increased the baseline acc.

### CNN

Accuracy, loss **before switching XIL on** (same for all):  
train acc= 99.44% (±0.15); test acc= 59.03% (±2.04); train loss= 7.19e-05; test loss=0.00746 

**After 50 epochs training with XIL loss**:  
|    Method     | train acc         | test acc     | train loss | test loss |
| ------------- |:-----------------:| :-----------:| :---------:| :--------:|
| RRR (100)     | 91.5% (±0.99)     | 87.7% (±0.29)| 0.000972   | 0.006444  |
| RBR (1M)      | 99.6% (±0.20)     | 59.7  (±1.50)| 0.003970   | 0.007437  |
| CE (60k)      | 99.1% (±0.15)     | 87.2% (±0.14)| 0.000137   | 0.006350  |

## Feedback quality
This experiment asks the question of **How does the feedack quality influence the perfromance of the XIL methods?**  
We modeled four cases, which also include sanity checks. Listed are the following cases: Uncertain, incomplete, adversarial, wrong feedback?  

Details about the cases:  
* Uncertain feedback: Random masks: $A \in \text{randint}(\{0,1\})$
* Incomplete feedback: Subregion $S$ of the (un)important parts in the mask $A = 
    \begin{cases} 1, & \text{if}\ a_i \in S \\ 0, & \text{otherwise} \end{cases}$.  
    In our case we chose the bottom half of a square as $S$
* Adversarial feedback: All-one binary masks $A \in \{1\}$ 
* Wrong feedback: 5x3 rectangle region on top/bottom/right/left middle border (opposite site to real confounder square).  

We only evaluated XIL methods that increases the baseline performance. We used rr_clipping in RBR
  
**CNN: Mean accuracies train and test:**
|    Method     |$feedback->$| random  | wrong        | incomlete    |  adversarial | correct      |
| ------------- |:------|:------------:| :-----------:| :-----------:| :-----------:|:------------:|
| RRR (100)     | train | 83.4% (±0.31)| 99.3% (±0.25)| 99.1% (±0.12)| 81.7% (±0.48)| 98.7% (±0.32)|
|               | test  | 72.4% (±1.09)| 56.7% (±1.51)| 84.4% (±0.77)| 72.5% (±1.81)| 89.4% (±0.40)|
| RBR (1M)      | train | 99.5% (±0.12)| 92.4% (±2.38)| 96.1% (±2.13)| 99.5% (±0.19)| 96.6% (±2.29)|     
|               | test  | 59.2% (±2.70)| 64.9% (±4.43)| 74.7% (±0.84)| 59.3% (±2.81)| 83.4% (±0.80)|
| CE (60k)      | train | 98.1% (±0.40)| 99.6% (±0.06)| 99.5% (±0.08)| 54.8% (±0.16)| 99.1% (±0.15)| 
|               | test  | 59.9% (±0.64)| 59.3% (±1.74)| 62.6% (±1.54)| 61.6% (±1.75)| 87.7% (±0.79)|
  
--> **Interpretation:**  
* **Random**: Random feedback does not improve the performance. We attribute the higher test acc in RRR to the lower train acc (Basline model at 80% train acc also reaches 73% test acc).
* **Wrong**: All methods pass the sanity check. Wrong feedback equalizes approx. the baseline acc on test set - confounders are not overcome.
* **Incomplete**: RRR and RBR both perform better on test acc compared to the no XIL baseline (+25%, +15%), indicating that providing incomplete feedback still offers enough information to overcome the confounder partly. In contrast the CE method falls back to almost baseline test accuracy. We follow that RRR,RBR incorporate partial feedback better.   
* **Adversarial**: Adversarial feedback does not improve the test acc. Again we attribute the higher test acc in RRR to the lower train acc as in the case of random feedback. 

## Interaction efficiancy

**Mean accuracies train and test:** 
|    Method     |       | 25           | 50           |        100   |       200    |          400 |          800 |         1600 |         5000 |        10000 |       20000  |     60000   |
| ------------- |:------|:------------:| :-----------:| :-----------:| :-----------:|:------------:|:------------:| :-----------:| :-----------:| :-----------:|:------------:|:-----------:|
| RRR (100)     | train | 96.9% (±2.19)| 96.9% (±2.09)| 94.7% (±1.98)| 97.1% (±0.43)| 96.8% (±0.61)| 97.4% (±0.57)| 98.2% (±0.63)| 98.7% (±0.42)| 98.7% (±0.26)| 98.8% (±0.29)|98.7% (±0.32)|
|               | test  | 75.0% (±1.45)| 79.2% (±1.07)| 80.0% (±1.65)| 82.8% (±0.88)| 85.0% (±1.20)| 86.9% (±1.17)| 89.2% (±0.21)| 89.2% (±0.65)| 89.4% (±0.23)| 89.1% (±0.27)|89.4% (±0.40)|
| RBR (1M)      | train | 99.5% (±0.23)| ??% (±??)    | 97.6% (±1.95)| 93.8% (±2.93)| 89.0% (±1.28)| 89.6% (±1.39)| 91.2% (±1.84)| 92.6% (±1.99)| 94.0% (±2.15)| 92.0% (±2.93)|96.6% (±2.29)|
|               | test  | 59.9% (±1.82)| ??% (±??)    | 68.4% (±1.59)| 74.4% (±1.23)| 84.5% (±1.23)| 85.9% (±2.14)| 87.1% (±2.02)| 85.8% (±0.95)| 84.4% (±1.84)| 83.1% (±2.27)|83.4% (±0.80)|
| CE (n=1)      | train | 99.3% (±0.08)| 99.4% (±0.13)| 99.3% (±0.15)| 99.4% (±0.15)| 99.3% (±0.19)| 99.5% (±0.12)| 99.2% (±0.14)| 99.4% (±0.08)| 99.2% (±0.17)| 99.2% (±0.19)|99.1% (±0.15)|
|               | test  | 59.4% (±2.16)| 60.6% (±2.53)| 61.2% (±1.83)| 63.5% (±2.32)| 65.6% (±1.55)| 68.3% (±1.73)| 70.7% (±1.01)| 75.5% (±1.00)| 78.9% (±0.47)| 82.6% (±0.34)|87.7% (±0.79)|
  

* RBR: Because of the large reg rate the training process was quiet unstable and the model would sometimes not train (train acc), because the differences between a batch with XIL examples and without was to big. We therefore clipped the rr loss to a max of 1.0 per batch. 


## Switch XIL on
In this experiment we trained a simple cnn model for 50 epochs with cross entropy loss and after that we switched on the respective XIL loss and trained for another 50 epochs. We used the following setup:  
* Hyperparams: EPOCHS = 100, BATCH_SIZE = 256, LR = 0.001, optim=Adam, DISABLE_XIL_FOR_N_EPOCHS = 50, BASE_CRITERION = cross entropy  
* 5 runs with seeds [1,10,100,1000,10000]; in brackets regularizer_rate of XIL loss, besides CE (indicates the number of counterexamples n_instances)
* note: RBR...

### CNN
Accuracy, loss **before switching XIL on** (same for all):  
train acc= 99.24% (±0.08); test acc= 58.63% (±1.88); train loss= 0.000106; test loss= 0.007478  

**After 50 epochs training with XIL loss**:  
|    Method     | train acc  | test acc  | train loss | test loss |
| ------------- |:----------:| :--------:| :---------:| :--------:|
| RRR (10)      | 95.6% (±0.59)     | 87.4% (±0.68)    | 0.000532   | 0.006382  |
| RRRGradCam (1)| 92.3% (±3.58)     | 70.6% (±5.94)    | 0.001474   | 0.007065  |
| RBR (?)  ?    | ???      | ???    | ???    | ???   |
| CDEP (1k)     | 99.4% (±0.11)      | 57.5% (±1.58)    | 0.000076   | 0.007525  |
| HINT (100)    | 37.3% (±27.6)     | 35.9% (±26.66)    | 0.140821   | 0.008363  |
| CE (60k)      | 99.2% (±0.11)     | 87.3% (±0.50)    | 0.000112   | 0.006354  |
